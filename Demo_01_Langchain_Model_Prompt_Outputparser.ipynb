{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhilash0203/toolteam/blob/main/Demo_01_Langchain_Model_Prompt_Outputparser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Demo: Langchain Model Prompt Outputparser**"
      ],
      "metadata": {
        "id": "g_gBxYH8kIqp"
      },
      "id": "g_gBxYH8kIqp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Steps to Perform:**\n",
        "\n",
        "1. Set up the Environment\n",
        "2. Call Direct API to OpenAI\n",
        "3. Call the Direct API at OpenAI\n",
        "4. Use the Chat Model\n",
        "5. Format a New Message\n",
        "6. Generate a Response in a New Style\n",
        "7. Output Parsers\n",
        "8. Use the Output Parser"
      ],
      "metadata": {
        "id": "sx4ZUW69kPdR"
      },
      "id": "sx4ZUW69kPdR"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zPGQHERQiUDm"
      },
      "id": "zPGQHERQiUDm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: Set up the Environment**\n",
        "\n",
        "\n",
        "\n",
        "*   Install the required packages and configure the environment, including OpenAI and LangChain, for making API calls.\n",
        "*   Import essential modules and set up the OpenAI API key for making direct API calls to OpenAI through langchain.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SW2hyf3cE_4g"
      },
      "id": "SW2hyf3cE_4g"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25e19e5c-ae2c-4d86-984d-488bae1e04c0",
      "metadata": {
        "id": "25e19e5c-ae2c-4d86-984d-488bae1e04c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcd83fb7-97b5-47fa-f118-7f0102bc10df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.17)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.36)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.48)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.52)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.48->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28\n",
        "!pip install langchain\n",
        "import os\n",
        "import openai\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mxUGAb0BYyqC"
      },
      "id": "mxUGAb0BYyqC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tXyNikZ6Yse8"
      },
      "id": "tXyNikZ6Yse8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2: Call the Direct API at OpenAI**\n",
        "\n",
        "\n",
        "\n",
        "*   Create a function called **get_completion** that receives a prompt and model as input and provides a completion as output.\n",
        "*   Verify the functionality of the function by asking a straightforward question, such as **What is 1+1?**."
      ],
      "metadata": {
        "id": "wJ7Vf0liFig7"
      },
      "id": "wJ7Vf0liFig7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e120e00f-5f45-43a9-8b5a-93b20ff6b797",
      "metadata": {
        "id": "e120e00f-5f45-43a9-8b5a-93b20ff6b797"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0,\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8be4dbce-5ecd-44e3-a54f-582790efc014",
      "metadata": {
        "id": "8be4dbce-5ecd-44e3-a54f-582790efc014",
        "outputId": "32f50178-1ff7-46f1-a7c2-c5f5b9171f3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1+1 equals 2.\n"
          ]
        }
      ],
      "source": [
        "openai.api_key = \"sk-proj-snmAobrEap4kwDai19mvT3BlbkFJajzBKuIprjn4IthhYB2m\"\n",
        "print(get_completion(\"What is 1+1?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Call API Through LangChain**\n",
        "\n",
        "\n",
        "\n",
        "*   Use LangChain by creating an instance of the ChatOpenAI class.\n",
        "*   Modify parameters like **customer_style** and **customer_email** to influence the tone and formality of the generated responses.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Oe-lkvcsHBpZ"
      },
      "id": "Oe-lkvcsHBpZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c34a80a1-14e6-4eb0-a0f4-4753f215e571",
      "metadata": {
        "id": "c34a80a1-14e6-4eb0-a0f4-4753f215e571"
      },
      "outputs": [],
      "source": [
        "# Start by creating an instance of the ChatOpenAI class.\n",
        "chat = ChatOpenAI(api_key=openai.api_key,temperature=0.0)\n",
        "\n",
        "# Define a template for our prompts.\n",
        "template_string = \"\"\"Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\"\"\"\n",
        "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
        "\n",
        "# Use this template to format our messages.\n",
        "customer_style = \"American English in a casual tone\"\n",
        "customer_email = \"\"\"\n",
        "I'm super excited about the new gaming console I bought! It arrived in just 2 days and I've been playing non-stop. Totally worth the price!\n",
        "\"\"\"\n",
        "\n",
        "customer_messages = prompt_template.format_messages(\n",
        "                    style=customer_style,\n",
        "                    text=customer_email)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 4: Use the Chat Model**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Use the ChatOpenAI instance to produce a response in the designated style, aligning with the formatted messages.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "juFhjkD3HNC5"
      },
      "id": "juFhjkD3HNC5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfc06b78-7329-4eec-a7ae-b4d5289edce0",
      "metadata": {
        "id": "dfc06b78-7329-4eec-a7ae-b4d5289edce0",
        "outputId": "ccf6cf7f-7ca1-4d82-cabe-51b98b233ddd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm so pumped about the new gaming console I got! It came in just 2 days and I've been playing non-stop. Definitely worth the money!\n"
          ]
        }
      ],
      "source": [
        "# Use our ChatOpenAI instance to generate a response.\n",
        "customer_response = chat(customer_messages)\n",
        "print(customer_response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5: Format a New Message**\n",
        "\n",
        "\n",
        "*   Format the newly created message in the designated style, preparing it for interaction with the chat model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F5MQfocOIYUz"
      },
      "id": "F5MQfocOIYUz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a23d343-ea4a-49ba-96df-964508d220f5",
      "metadata": {
        "id": "7a23d343-ea4a-49ba-96df-964508d220f5",
        "outputId": "10809471-745d-4f62-80f6-4c064f8f6559",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translate the text that is delimited by triple backticks into a style that is a cheerful tone that speaks in English Pirate. text: ```Hey there, we're glad you're enjoying your new gaming console. Game on!```\n"
          ]
        }
      ],
      "source": [
        "# Format a new message using a different style.\n",
        "service_reply = \"Hey there, we're glad you're enjoying your new gaming console. Game on!\"\n",
        "service_style_pirate = \"a cheerful tone that speaks in English Pirate\"\n",
        "service_messages = prompt_template.format_messages(style=service_style_pirate, text=service_reply)\n",
        "print(service_messages[0].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 6: Generate a Response in a New Style**\n",
        "\n",
        "\n",
        "*   Retrieve the generated response, in this case, would be in the manner of a polite English Pirate.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pUsg6O24IlNV"
      },
      "id": "pUsg6O24IlNV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af52bbad-116f-4ad9-9471-f11389be379e",
      "metadata": {
        "id": "af52bbad-116f-4ad9-9471-f11389be379e",
        "outputId": "d626b2af-64b3-44e0-fe82-ce5affa1a1d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ahoy there, me hearties! We be pleased as a parrot in a treasure chest to hear ye be enjoyin' yer new gaming console. Keep on playin', me matey! Arrr!\n"
          ]
        }
      ],
      "source": [
        "# Generate a response in our new style using the ChatOpenAI instance.\n",
        "service_response = chat(service_messages)\n",
        "print(service_response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 7: Output Parsers**\n",
        "\n",
        "\n",
        "*   Clearly outline the preferred format for the language model's output using an output parser.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LMgWoftUI2E4"
      },
      "id": "LMgWoftUI2E4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ab54bea-72ae-4db1-bc0d-25ca66a6c052",
      "metadata": {
        "id": "4ab54bea-72ae-4db1-bc0d-25ca66a6c052"
      },
      "outputs": [],
      "source": [
        "# Define how we would like the output from the language model to look like.\n",
        "desired_output = {\n",
        "    \"gift\": False,\n",
        "    \"delivery_days\": 2,\n",
        "    \"price_value\": \"Totally worth the price!\"\n",
        "}\n",
        "\n",
        "# Create a customer review and a template for extracting information from the review.\n",
        "customer_review = \"\"\"\\\n",
        "I'm super excited about the new gaming console I bought! It arrived in just 2 days and I've been playing non-stop. Totally worth the price!\n",
        "\"\"\"\n",
        "\n",
        "review_template = \"\"\"\\\n",
        "For the following text, extract the following information:\n",
        "gift: Was the item purchased as a gift for someone else? \\\n",
        "Answer True if yes, False if not or unknown.\n",
        "delivery_days: How many days did it take for the product \\\n",
        "to arrive? If this information is not found, output -1.\n",
        "price_value: Extract any sentences about the value or price,\\\n",
        "and output them as a comma separated Python list.\n",
        "Format the output as JSON with the following keys:\n",
        "gift\n",
        "delivery_days\n",
        "price_value\n",
        "text: {text}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 8: Use the Output Parser**\n",
        "\n",
        "\n",
        "*   Use the defined schemas to instantiate the **StructuredOutputParser** class, forming an instance named **output_parser**.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "irshmpi-JDBI"
      },
      "id": "irshmpi-JDBI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "704af701-ab09-40ff-88f9-46c8797e27a0",
      "metadata": {
        "id": "704af701-ab09-40ff-88f9-46c8797e27a0"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
        "gift_schema = ResponseSchema(name=\"gift\",\n",
        "description=\"Was the product given as a present to someone? \\\n",
        "Answer True if yes, False if not or unknown.\")\n",
        "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
        "description=\"How many days was the delivery period for the product? \\\n",
        "If this information is not found, output -1.\")\n",
        "price_value_schema = ResponseSchema(name=\"price_value\",\n",
        "description=\"Extract any sentences about the cost or value of the product, \\\n",
        "and output them as a comma separated Python list.\")\n",
        "response_schemas = [gift_schema, delivery_days_schema, price_value_schema]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use these format instructions to create a new prompt, generate a response, and parse the output."
      ],
      "metadata": {
        "id": "87qXvbN2JZcJ"
      },
      "id": "87qXvbN2JZcJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4e2b570-4c61-41ad-aa5d-fc9e18f27a06",
      "metadata": {
        "id": "b4e2b570-4c61-41ad-aa5d-fc9e18f27a06"
      },
      "outputs": [],
      "source": [
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e68b0f1b-06cb-4ddb-b8d3-0edb2a5d611d",
      "metadata": {
        "id": "e68b0f1b-06cb-4ddb-b8d3-0edb2a5d611d"
      },
      "outputs": [],
      "source": [
        "format_instructions = output_parser.get_format_instructions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47a4af5d-bb0a-4f92-b4d6-0039d21977f6",
      "metadata": {
        "id": "47a4af5d-bb0a-4f92-b4d6-0039d21977f6",
        "outputId": "8c5b434c-5ac9-43d5-a5c9-65547621d4a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"gift\": string  // Was the product given as a present to someone? Answer True if yes, False if not or unknown.\n",
            "\t\"delivery_days\": string  // How many days was the delivery period for the product? If this information is not found, output -1.\n",
            "\t\"price_value\": string  // Extract any sentences about the cost or value of the product, and output them as a comma separated Python list.\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "print(format_instructions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(template=review_template)\n",
        "messages = prompt.format_messages(text=customer_review, format_instructions=format_instructions)\n",
        "\n",
        "response = chat(messages)\n",
        "output_dict = output_parser.parse(response.content)"
      ],
      "metadata": {
        "id": "-Xjtw5S-60kt"
      },
      "id": "-Xjtw5S-60kt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_dict)"
      ],
      "metadata": {
        "id": "cz3X108I605R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f000c3-d3a7-4db9-aa81-b070966e52e0"
      },
      "id": "cz3X108I605R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'gift': False, 'delivery_days': 2, 'price_value': ['Totally worth the price!']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_dict.get('gift'))"
      ],
      "metadata": {
        "id": "cS17iq6m7EJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf667970-f837-4617-b0dd-eb88fe76ddea"
      },
      "id": "cS17iq6m7EJY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion:**\n",
        "In this activity, you successfully configured the environment, utilized OpenAI's Direct API, interacted with the Chat Model, formatted messages, generated responses, and employed output parsers. The process was efficient and demonstrated effective communication with the OpenAI models."
      ],
      "metadata": {
        "id": "3T4_T6V0JoPJ"
      },
      "id": "3T4_T6V0JoPJ"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nwAXmuQGKqbb"
      },
      "id": "nwAXmuQGKqbb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}